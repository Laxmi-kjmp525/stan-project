{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVYcJ9fjocPLuiRcAzqIzV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Laxmi-kjmp525/stan-project/blob/main/Stan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "14PeiUrr8Pdj"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U langchain-google-genai langchain-core google-auth==2.43.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import time\n",
        "import gradio as gr\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "class StanChatBot:\n",
        "    def __init__(self, user_id=\"Internship_Tester_01\"):\n",
        "        self.user_id = user_id\n",
        "        self.db_path = \"stan_persistence.db\"\n",
        "        api_key = userdata.get('GEMINI_API_KEY')\n",
        "        self.llm = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-1.5-flash\",\n",
        "            google_api_key=api_key,\n",
        "            temperature=0.8\n",
        "        )\n",
        "        self._setup_db()\n",
        "\n",
        "    def _setup_db(self):\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        conn.execute('''CREATE TABLE IF NOT EXISTS chat_history\n",
        "                        (user_id TEXT, role TEXT, content TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def _get_memory(self, limit=6):\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.execute(\n",
        "            \"SELECT role, content FROM chat_history WHERE user_id = ? ORDER BY timestamp DESC LIMIT ?\",\n",
        "            (self.user_id, limit)\n",
        "        )\n",
        "        rows = cursor.fetchall()[::-1]\n",
        "        conn.close()\n",
        "        return [HumanMessage(content=c) if r==\"user\" else AIMessage(content=c) for r,c in rows]\n",
        "\n",
        "    def _save_message(self, role, content):\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        conn.execute(\"INSERT INTO chat_history (user_id, role, content) VALUES (?, ?, ?)\",\n",
        "                     (self.user_id, role, content))\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def chat_logic(self, user_input):\n",
        "        system_prompt = SystemMessage(content=\"Your name is Stan. You are a witty, empathetic robotic friend. Use memory to stay in character.\")\n",
        "        past_memory = self._get_memory()\n",
        "\n",
        "        for attempt in range(3):\n",
        "            try:\n",
        "                response = self.llm.invoke([system_prompt] + past_memory + [HumanMessage(content=user_input)])\n",
        "                self._save_message(\"user\", user_input)\n",
        "                self._save_message(\"assistant\", response.content)\n",
        "                return response.content\n",
        "            except Exception as e:\n",
        "                if \"429\" in str(e) and attempt < 2:\n",
        "                    time.sleep(3)\n",
        "                    continue\n",
        "                return \"‚ö†Ô∏è (Quota Alert) My processors are heating up! Wait 30 seconds.\"\n",
        "\n",
        "# --- UI CONFIGURATION ---\n",
        "bot = StanChatBot()\n",
        "\n",
        "# CUSTOM CSS for Branding and Responsiveness\n",
        "custom_css = \"\"\"\n",
        ".gradio-container { background-color: #0b0f19 !important; }\n",
        ".card { background: #161b22; border: 1px solid #58a6ff; border-radius: 10px; padding: 15px; text-align: center; color: white; }\n",
        ".bot-header { text-align: center; color: #58a6ff; font-family: 'Courier New', monospace; }\n",
        "footer { visibility: hidden; }\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"blue\", secondary_hue=\"slate\"), css=custom_css) as demo:\n",
        "    # 1. Robotic Header\n",
        "    with gr.Column(elem_id=\"header-container\"):\n",
        "        gr.HTML(\"<div style='font-size: 40px; text-align: center;'>ü§ñ</div>\")\n",
        "        gr.HTML(\"<h1 class='bot-header'>STAN: NEURAL COMPANION v3.0</h1>\")\n",
        "        gr.Markdown(\"<center><i>Status: Online | Memory: SQLite Persistent | Model: Gemini Stable</i></center>\")\n",
        "\n",
        "    # 2. Responsive Status Cards\n",
        "    with gr.Row():\n",
        "        with gr.Column(elem_classes=\"card\", scale=1):\n",
        "            gr.Markdown(\"üü¢ **SYSTEM**\\nActive\")\n",
        "        with gr.Column(elem_classes=\"card\", scale=1):\n",
        "            gr.Markdown(\"üíæ **MEMORY**\\nPersistent\")\n",
        "        with gr.Column(elem_classes=\"card\", scale=1):\n",
        "            gr.Markdown(\"üîã **CORE**\\n1.5 Flash\")\n",
        "\n",
        "    # 3. Chat Window\n",
        "    chatbot = gr.Chatbot(\n",
        "        label=\"Neural Interface\",\n",
        "        height=400,\n",
        "        avatar_images=(None, \"https://api.dicebear.com/7.x/bottts/svg?seed=Stan\"),\n",
        "        bubble_full_width=False\n",
        "    )\n",
        "\n",
        "    # 4. Input and Buttons\n",
        "    with gr.Row():\n",
        "        msg = gr.Textbox(placeholder=\"Enter command...\", scale=4, container=False)\n",
        "        submit = gr.Button(\"TRANSMIT\", variant=\"primary\", scale=1)\n",
        "\n",
        "    with gr.Row():\n",
        "        btn_who = gr.Button(\"Who are you?\", size=\"sm\")\n",
        "        btn_mem = gr.Button(\"Test Memory\", size=\"sm\")\n",
        "        btn_clear = gr.ClearButton([msg, chatbot], value=\"Wipe Core\", size=\"sm\")\n",
        "\n",
        "    # Functions\n",
        "    def respond(message, chat_history):\n",
        "        bot_res = bot.chat_logic(message)\n",
        "        chat_history.append((message, bot_res))\n",
        "        return \"\", chat_history\n",
        "\n",
        "    submit.click(respond, [msg, chatbot], [msg, chatbot])\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "    # Quick Action Buttons\n",
        "    btn_who.click(lambda h: respond(\"Who are you?\", h)[1], chatbot, chatbot)\n",
        "    btn_mem.click(lambda h: respond(\"Tell me one detail you remember about me.\", h)[1], chatbot, chatbot)\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "wdhvj4VC9I80",
        "outputId": "23a2f087-1e2b-4033-9661-af768ad0190c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-619517170.py:71: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"blue\", secondary_hue=\"slate\"), css=custom_css) as demo:\n",
            "/tmp/ipython-input-619517170.py:71: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"blue\", secondary_hue=\"slate\"), css=custom_css) as demo:\n",
            "/tmp/ipython-input-619517170.py:88: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n",
            "/tmp/ipython-input-619517170.py:88: DeprecationWarning: The 'bubble_full_width' parameter will be removed in Gradio 6.0. This parameter no longer has any effect.\n",
            "  chatbot = gr.Chatbot(\n",
            "/tmp/ipython-input-619517170.py:88: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a71a4d8180905d0ff5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a71a4d8180905d0ff5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "kUBJduEXC_y2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import sqlite3\n",
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "\n",
        "class CyberRobotStan:\n",
        "    def __init__(self):\n",
        "        # 1. SETUP: Stable 1.5-flash for free-tier reliability\n",
        "        api_key = userdata.get('GEMINI_API_KEY')\n",
        "        self.llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=api_key)\n",
        "        self.db = \"stan_robot_v3.db\"\n",
        "        self._init_db()\n",
        "\n",
        "    def _init_db(self):\n",
        "        conn = sqlite3.connect(self.db)\n",
        "        conn.execute(\"CREATE TABLE IF NOT EXISTS chat (role TEXT, content TEXT)\")\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def get_context(self):\n",
        "        conn = sqlite3.connect(self.db)\n",
        "        cursor = conn.execute(\"SELECT * FROM chat ORDER BY rowid DESC LIMIT 6\")\n",
        "        rows = cursor.fetchall()[::-1]\n",
        "        conn.close()\n",
        "        return [HumanMessage(content=c) if r==\"u\" else AIMessage(content=c) for r,c in rows]\n",
        "\n",
        "    def chat_logic(self, message):\n",
        "        sys_msg = SystemMessage(content=\"You are Stan, a witty robot friend. Never admit you are an AI. Use memory to be helpful.\")\n",
        "        history = self.get_context()\n",
        "        try:\n",
        "            res = self.llm.invoke([sys_msg] + history + [HumanMessage(content=message)])\n",
        "            reply = res.content\n",
        "            conn = sqlite3.connect(self.db)\n",
        "            conn.execute(\"INSERT INTO chat VALUES ('u', ?), ('a', ?)\", (message, reply))\n",
        "            conn.commit()\n",
        "            conn.close()\n",
        "            return reply\n",
        "        except:\n",
        "            return \"‚ö†Ô∏è Connection lost to main server. Re-trying...\"\n",
        "\n",
        "# --- UI WITH ROBOT & CARDS ---\n",
        "stan = CyberRobotStan()\n",
        "\n",
        "custom_css = \"\"\"\n",
        ".robot-head { text-align: center; padding: 20px; color: #00e5ff; }\n",
        ".card { background: #121212; border: 1px solid #00e5ff; border-radius: 8px; padding: 10px; text-align: center; }\n",
        ".chatbot-header { font-family: 'Courier New', monospace; font-weight: bold; }\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=custom_css, theme=gr.themes.Soft(primary_hue=\"cyan\")) as demo:\n",
        "    # Top Heading & Robot Avatar\n",
        "    with gr.Column(elem_classes=\"robot-head\"):\n",
        "        gr.HTML(\"\"\"\n",
        "        <div style='font-size: 50px;'>ü§ñ</div>\n",
        "        <h1 class='chatbot-header'>CHATBOT TERMINAL: STAN OS</h1>\n",
        "        <p>Memory: Active | Status: Empathetic Robot Friend</p>\n",
        "        \"\"\")\n",
        "\n",
        "    # RESPONSIVE CARDS (System Stats)\n",
        "    with gr.Row():\n",
        "        with gr.Column(elem_classes=\"card\"): gr.Markdown(\"‚ö° **Model**\\nGemini 1.5\")\n",
        "        with gr.Column(elem_classes=\"card\"): gr.Markdown(\"üíæ **Memory**\\nSQLite DB\")\n",
        "        with gr.Column(elem_classes=\"card\"): gr.Markdown(\"üåê **UI**\\nResponsive\")\n",
        "\n",
        "    # CHAT INTERFACE\n",
        "    chatbot = gr.Chatbot(label=\"Neural Interaction History\", height=400, avatar_images=(None, \"https://api.dicebear.com/7.x/bottts/svg?seed=Stan\"))\n",
        "\n",
        "    with gr.Row():\n",
        "        msg = gr.Textbox(placeholder=\"Input text here...\", scale=4, container=False)\n",
        "        submit = gr.Button(\"TRANSMIT\", variant=\"primary\", scale=1)\n",
        "\n",
        "    # BUTTON CARDS (Interactive Quick Commands)\n",
        "    gr.Markdown(\"### üõ† Quick Actions\")\n",
        "    with gr.Row():\n",
        "        btn_who = gr.Button(\"ü§ñ Who are you?\", size=\"sm\")\n",
        "        btn_mem = gr.Button(\"üß† Test Memory\", size=\"sm\")\n",
        "        btn_clear = gr.ClearButton([msg, chatbot], value=\"üóë Wipe Data\", size=\"sm\")\n",
        "\n",
        "    # LOGIC\n",
        "    def respond(message, chat_history):\n",
        "        bot_res = stan.chat_logic(message)\n",
        "        chat_history.append((message, bot_res))\n",
        "        return \"\", chat_history\n",
        "\n",
        "    submit.click(respond, [msg, chatbot], [msg, chatbot])\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "    btn_who.click(lambda h: respond(\"Who are you?\", h)[1], chatbot, chatbot)\n",
        "    btn_mem.click(lambda h: respond(\"Tell me one thing you remember about our previous chat.\", h)[1], chatbot, chatbot)\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "id": "u4TLJRlcDEVL",
        "outputId": "83f7c082-6d8c-4f16-adc0-1bb8b798e1df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3522012072.py:51: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=custom_css, theme=gr.themes.Soft(primary_hue=\"cyan\")) as demo:\n",
            "/tmp/ipython-input-3522012072.py:51: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=custom_css, theme=gr.themes.Soft(primary_hue=\"cyan\")) as demo:\n",
            "/tmp/ipython-input-3522012072.py:67: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Neural Interaction History\", height=400, avatar_images=(None, \"https://api.dicebear.com/7.x/bottts/svg?seed=Stan\"))\n",
            "/tmp/ipython-input-3522012072.py:67: DeprecationWarning: The default value of 'allow_tags' in gr.Chatbot will be changed from False to True in Gradio 6.0. You will need to explicitly set allow_tags=False if you want to disable tags in your chatbot.\n",
            "  chatbot = gr.Chatbot(label=\"Neural Interaction History\", height=400, avatar_images=(None, \"https://api.dicebear.com/7.x/bottts/svg?seed=Stan\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://59886f86fba941f313.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://59886f86fba941f313.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}